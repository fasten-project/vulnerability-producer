/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package eu.fasten.vulnerabilityproducer;

import com.google.gson.Gson;
import com.mongodb.client.MongoDatabase;
import eu.fasten.vulnerabilityproducer.db.NitriteController;
import eu.fasten.vulnerabilityproducer.utils.Vulnerability;
import eu.fasten.vulnerabilityproducer.utils.connections.JavaHttpClient;
import eu.fasten.vulnerabilityproducer.utils.connections.KafkaConnector;
import eu.fasten.vulnerabilityproducer.utils.parsers.ParserManager;
import org.apache.commons.io.FileUtils;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.dizitart.no2.exceptions.NitriteIOException;
import org.json.JSONArray;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.File;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.List;

public class VulnerabilityProducer {
    //        Kafka        //
    private List<String> serverAddresses;
    public String topic;
    public static final String groupId = "vulnerability";
    private KafkaProducer<String, String> kafkaProducer;

    //        Utils        //
    private ParserManager parserManager;
    private MongoDatabase mongoDatabase;
    public String pathToMnt;
    private final Logger logger = LoggerFactory.getLogger(VulnerabilityProducer.class.getName());

    public void setPathToMnt(String mnt) {
        this.pathToMnt = mnt + "/vuln/producer";
    }

    public void setKafkaTopic(String topic) {
        this.topic = topic;
    }

    public void setKafkaProducer(KafkaProducer<String, String> kafkaProducer) {
        this.kafkaProducer = kafkaProducer;
    }

    public void setServerAddresses(List<String> serverAddresses) {
        this.serverAddresses = serverAddresses;
    }

    public void setMongoDatabase(MongoDatabase mongoDatabase) {
        this.mongoDatabase = mongoDatabase;
    }

    /**
     * Sets the connection to Mongodb instance.
     */
    public void createParserManager(String inferStrategy) throws IOException {
        logger.info("Creating the ParserManager");
        var client = new JavaHttpClient();
        NitriteController nc = null;
        try {
            nc = new NitriteController(pathToMnt + "/nitrite/security.db");
        } catch (NitriteIOException ne) {
            logger.info("Concurrent access to cache detected - Proceeding without it.");
        }
        var ghToken = System.getenv("FASTEN_GHTOKEN");
        this.parserManager = new ParserManager(client, this.mongoDatabase, nc, ghToken, pathToMnt, inferStrategy);
    }

    /**
     * Method to create a KafkaProducer in order to publish information
     * @return
     */
    public void createKafkaProducer() {
        var p = KafkaConnector.kafkaProducerProperties(this.serverAddresses, groupId);
        this.kafkaProducer = new KafkaProducer<>(p);
    }

    /**
     * Starting point of the plugin.
     * Sets up the ParserManager.
     * First gets everything from parsers, then only looks for updates
     */
    public void start(boolean updateOnly, String inferStrategy) throws IOException {
        createParserManager(inferStrategy);

        // Get all the information
        if (!updateOnly)
            parserManager.getVulnerabilitiesFromParsers(kafkaProducer, topic);

        // Sleep and get updates from parser manager
        while (true) {
            logger.info("Sleeping a day, see you in a bit");
            parserManager.sleep();
            parserManager.getUpdatesFromParsers(kafkaProducer, topic);
        }
    }

    /**
     * Reads vulnerabilities from a JSON file.
     * Used for the demo
     * @param jsonPath - Path to JSON file
     */
    public void getVulnerabilitiesFromJson(String jsonPath) {
        // Read the content from the file
        var file = new File(jsonPath);
        String raw = null;
        try {
            raw = FileUtils.readFileToString(file, StandardCharsets.UTF_8);
        } catch (IOException e) {
            e.printStackTrace();
        }
        if (raw == null) return;
        // Parse the JSON
        var vulnArray = new JSONArray(raw);
        var gson = new Gson();
        for (int i = 0; i < vulnArray.length(); i++) {
            var v = gson.fromJson(vulnArray.getJSONObject(i).toString(), Vulnerability.class);
            logger.info("Publishing " + v.getId() + " to Kafka");
            kafkaProducer.send(new ProducerRecord<>(topic, v.toJson()));
        }
    }

    /**
     * Helper handler to launch the crawler evaluation
     */
    public void evaluateCrawler() {
        createParserManager();
        parserManager.evaluateCrawler();
    }
}
