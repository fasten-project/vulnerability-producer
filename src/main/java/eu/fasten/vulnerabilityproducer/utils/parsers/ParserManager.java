/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package eu.fasten.vulnerabilityproducer.utils.parsers;

import com.mongodb.client.MongoDatabase;
import eu.fasten.vulnerabilityproducer.db.NitriteController;
import eu.fasten.vulnerabilityproducer.utils.PatchFinderFactory;
import eu.fasten.vulnerabilityproducer.utils.Vulnerability;
import eu.fasten.vulnerabilityproducer.utils.connections.JavaHttpClient;
import eu.fasten.vulnerabilityproducer.utils.mappers.PurlMapper;
import eu.fasten.vulnerabilityproducer.utils.mappers.VersionRanger;
import me.tongfei.progressbar.ProgressBar;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.jooq.tools.json.JSONParser;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;
import java.util.stream.IntStream;

/**
 * The responsibility of the ParserManager is to gather Vulnerabilities from all the parsers.
 * Combine them together, merging what is necessary and the handing them over to the PatchFarmer to enrich
 * every single vulnerability with information about patches specifically.
 */
public class ParserManager {
    private ExtraParser extraParser;
    private GHParser ghParser;
    private NVDParser nvdParser;
    private OVALParser ovalParser;
    private OSSFuzzParser ossFuzzParser;
    private PatchFinderFactory patchFinderFactory;
    private final VersionRanger versionRanger;
    private final NitriteController nitriteController;
    private final KafkaProducer<String, String> kafkaProducer;
    private final String kafkaTopic;
    private PurlMapper purlMapper;
    private final Logger logger = LoggerFactory.getLogger(ParserManager.class.getName());
    private final String mnt;
    private static final Map<String, String> supportedForges =
            Map.of("mvn", "pkg:maven", "PyPI", "pkg:pypi", "debian", "pkg:deb/debian");
    private final int noParseWorkers = 5;

    public ParserManager(JavaHttpClient client,
                         MongoDatabase mongoDatabase,
                         NitriteController nitriteController,
                         String ghToken,
                         String mnt,
                         String inferStrategy,
                         KafkaProducer<String, String> kafkaProducer,
                         String kafkaTopic) throws IOException {
        Files.createDirectories(Path.of(mnt, "trackers"));
        Files.createDirectories(Path.of(mnt, "datasets"));
        Files.createDirectories(Path.of(mnt, "statements"));
        var ghsaStore = Files.createDirectories(Path.of(mnt, "ghsa_store"));

        this.mnt = mnt;
        this.nitriteController = nitriteController;
        this.versionRanger = new VersionRanger(client, mnt + "/trackers/package_versions.json");
        this.patchFinderFactory = new PatchFinderFactory(mongoDatabase, client, ghToken);
        this.extraParser   = new ExtraParser(client, versionRanger, mnt);
        this.ovalParser    = new OVALParser(client, versionRanger);
        this.ossFuzzParser = new OSSFuzzParser(mnt);
        this.ghParser      = new GHParser(client, ghToken, versionRanger, mnt + "/trackers/ghcursor.txt", ghsaStore);
        this.purlMapper    = new PurlMapper(versionRanger,mnt + "/datasets/purl_maps/", inferStrategy, client);
        this.nvdParser     = new NVDParser(new JSONParser(), client, mnt);
        this.kafkaProducer = kafkaProducer;
        this.kafkaTopic = kafkaTopic;
    }

    public void getVulnerabilitiesFromParsers(boolean updatesOnly) {
        if(updatesOnly) {
            logger.info("Updating Versions of Packages");
            versionRanger.updateMappings();
        }

        var vulnerabilities = parseVulnerabilities(updatesOnly);
        logger.info("Filtering out vulnerabilities without a forge");
        vulnerabilities = vulnerabilities.stream().filter(this::vulnerabilityForgeIsSupported).collect(Collectors.toList());

        logger.info("Injecting information about Patches");
        ProgressBar.wrap(vulnerabilities.parallelStream(), "InjectPatches").forEach((v) -> {
            try {
                var patchFinder = patchFinderFactory.getNewPatchFinder();
                logger.info("Inferring purls for " + v.getId());
                purlMapper.inferPurls(v, patchFinder);
                logger.info("Looking for patches in references of " + v.getId());
                patchFinder.parseReferences(v, nitriteController);
                logger.info("Publishing " + v.getId() + " to Kafka");
                emitKafkaMsg(v.toJson());
                storeStatement(v);
            } catch (Exception e) {
                logger.error("Could NOT process " + v.getId() + "\n" + e);
            }
        });
    }

    private List<Vulnerability> parseVulnerabilities(boolean updatesOnly) {

        var executor = Executors.newFixedThreadPool(noParseWorkers);
        List<Callable<HashMap<String, Vulnerability>>> parsingTasks = new ArrayList<>();
        parsingTasks.add(() -> {
            logger.info("Gathering vulnerabilities from GitHub Advisories");
            return ghParser.getVulnerabilities(updatesOnly);
        });
        parsingTasks.add(() -> {
            logger.info("Gathering vulnerabilities from Extra Sources");
            return  extraParser.getVulnerabilities(updatesOnly);
        });
        parsingTasks.add(() -> {
            logger.info("Gathering vulnerabilities from NVD");
            return nvdParser.getVulnerabilities(updatesOnly);
        });
        parsingTasks.add(() -> {
            logger.info("Gathering vulnerabilities from Debian OVAL");
            return ovalParser.getVulnerabilities(updatesOnly);
        });
        parsingTasks.add(() -> {
            logger.info("Gathering vulnerabilities from oss-fuzz-vulns");
            return ossFuzzParser.getVulnerabilities(updatesOnly);
        });

        try {
            List<Future<HashMap<String, Vulnerability>>> parsingResults = executor.invokeAll(parsingTasks);
            // Wait for the vulnerability parsers to finish their task.
            executor.shutdown();
            logger.info("Merging all the pulled vulnerabilities");
            var maps = new ArrayList<HashMap<String, Vulnerability>>();
            IntStream.range(0, noParseWorkers).forEachOrdered(t -> {
                try {
                    maps.add(parsingResults.get(t).get());
                } catch (InterruptedException | ExecutionException e) {
                    throw new RuntimeException(e);
                }
            });
            return mergeMapsOfVulnerabilities(maps);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

    private boolean vulnerabilityForgeIsSupported(Vulnerability v) {
        var basePurl = purlMapper.getPurlBase(v);
        if(basePurl == null) return false;
        return supportedForges.values()
                .stream()
                .anyMatch(forge -> basePurl.matches(forge + "/.*"));
    }

    public void storeStatement(Vulnerability v) {
        try {
            Files.writeString(Path.of(this.mnt + "/statements/" + v.getId() + ".json"), v.toJson());
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    /**
     * Given a list of vulnerability objects, it merges all of the objects.
     * @param maps - List of hashmaps mapping ID to Vulnerability objects
     * @return set of vulnerabilities
     */
    private List<Vulnerability> mergeMapsOfVulnerabilities(List<HashMap<String, Vulnerability>> maps) {
        var mapMerger = new HashMap<String, Vulnerability>();
        maps.forEach(map -> map.keySet().forEach(vId -> {
            if (mapMerger.containsKey(vId)) {
                var v = mapMerger.get(vId);
                v.merge(map.get(vId));
                mapMerger.put(vId, v);
            } else {
                mapMerger.put(vId, map.get(vId));
            }
        }));
        return mapMerger.values().stream().sorted().collect(Collectors.toList());
    }


    /**
     * Helper function for the vulnerability Plugin to inject the sleep behaviour.
     * This way, when mocking the parser, you can just skip over the wait.
     */
    public void sleep() {
        try {
            TimeUnit.DAYS.sleep(1);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    /**
     * Helper method to inject parsers and test the merging of the three sources.
     *
     * @param nvdParser   - NVDParser
     * @param ghParser    - GHParser
     * @param extraParser - ExtraParser
     * @param patchFinderFactory - PatchFinderFactory
     */
    public void injectParsers(NVDParser nvdParser,
                              GHParser ghParser,
                              ExtraParser extraParser,
                              OVALParser ovalParser,
                              OSSFuzzParser ossFuzzParser,
                              PatchFinderFactory patchFinderFactory,
                              PurlMapper purlMapper) {
        this.nvdParser = nvdParser;
        this.ghParser = ghParser;
        this.extraParser = extraParser;
        this.ovalParser = ovalParser;
        this.ossFuzzParser = ossFuzzParser;
        this.patchFinderFactory = patchFinderFactory;
        this.purlMapper = purlMapper;
    }

    private void emitKafkaMsg(String msg) {
        kafkaProducer.send(new ProducerRecord<>(kafkaTopic, msg), (recordMetadata, e) -> {
            if (e != null) {
                throw new RuntimeException(e);
            }
        });
    }
}
